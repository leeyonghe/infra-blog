---
layout: post
title: "MusicGen ëª¨ë¸ êµ¬í˜„ ì‹¬í™” ë¶„ì„ - AudioCraft Custom í”„ë¡œì íŠ¸"
date: 2024-12-20
categories: [AI, Deep Learning, Audio Generation]
tags: [AudioCraft, MusicGen, Text-to-Music, PyTorch, Neural Audio Generation]
author: "AI Blog"
---

# MusicGen ëª¨ë¸ êµ¬í˜„ ì‹¬í™” ë¶„ì„

AudioCraft Custom í”„ë¡œì íŠ¸ì˜ í•µì‹¬ì¸ MusicGen ëª¨ë¸ì˜ ë‚´ë¶€ êµ¬í˜„ì„ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤. ì´ í¬ìŠ¤íŠ¸ì—ì„œëŠ” `audiocraft/models/musicgen.py`ì˜ 339ì¤„ì— ê±¸ì¹œ ìƒì„¸í•œ êµ¬í˜„ì„ ì‚´í´ë³´ë©°, í…ìŠ¤íŠ¸ì—ì„œ ìŒì•…ì„ ìƒì„±í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì„ ì´í•´í•´ë³´ê² ìŠµë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨
1. [MusicGen í´ë˜ìŠ¤ êµ¬ì¡°](#musicgen-í´ë˜ìŠ¤-êµ¬ì¡°)
2. [ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë”©](#ì‚¬ì „-í›ˆë ¨ëœ-ëª¨ë¸-ë¡œë”©)
3. [ìƒì„± íŒŒë¼ë¯¸í„° ì„¤ì •](#ìƒì„±-íŒŒë¼ë¯¸í„°-ì„¤ì •)
4. [ì¡°ê±´ë¶€ ìƒì„± ë©”ì»¤ë‹ˆì¦˜](#ì¡°ê±´ë¶€-ìƒì„±-ë©”ì»¤ë‹ˆì¦˜)
5. [í† í° ìƒì„± ê³¼ì •](#í† í°-ìƒì„±-ê³¼ì •)
6. [ì„±ëŠ¥ ìµœì í™” ê¸°ë²•](#ì„±ëŠ¥-ìµœì í™”-ê¸°ë²•)

## MusicGen í´ë˜ìŠ¤ êµ¬ì¡°

### BaseGenModel ìƒì† ì•„í‚¤í…ì²˜

```python
class MusicGen(BaseGenModel):
    """MusicGen main model with convenient generation API.
    
    Args:
        name (str): name of the model.
        compression_model (CompressionModel): Compression model
            used to map audio to invertible discrete representations.
        lm (LMModel): Language model over discrete representations.
        max_duration (float, optional): maximum duration the model can produce,
            otherwise, inferred from the training params.
    """
```

MusicGenì€ `BaseGenModel`ì„ ìƒì†ë°›ì•„ êµ¬í˜„ë˜ë©°, ë‹¤ìŒê³¼ ê°™ì€ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

#### ğŸ“¦ ì£¼ìš” ì»´í¬ë„ŒíŠ¸
- **Compression Model**: ì˜¤ë””ì˜¤ë¥¼ ì—­ë³€í™˜ ê°€ëŠ¥í•œ ì´ì‚°ì  í‘œí˜„ìœ¼ë¡œ ë§¤í•‘
- **Language Model (LM)**: ì´ì‚°ì  í‘œí˜„ì— ëŒ€í•œ ì–¸ì–´ ëª¨ë¸
- **Conditioning Attributes**: í…ìŠ¤íŠ¸ ë° ë©œë¡œë”” ì¡°ê±´ ì²˜ë¦¬

#### ğŸ”§ ì´ˆê¸°í™” ê³¼ì •
```python
def __init__(self, name: str, compression_model: CompressionModel, lm: LMModel,
             max_duration: tp.Optional[float] = None):
    self.name = name
    self.compression_model = compression_model
    self.lm = lm
    # ëª¨ë“  ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
    self.compression_model.eval()
    self.lm.eval()
```

## ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë”©

### ëª¨ë¸ í¬ê¸°ë³„ ë³€í˜•

MusicGenì€ ë‹¤ì–‘í•œ í¬ê¸°ì˜ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ì œê³µí•©ë‹ˆë‹¤:

#### ğŸµ í‘œì¤€ ëª¨ë¸
- **small**: 300M íŒŒë¼ë¯¸í„°, ê²½ëŸ‰í™”ëœ ë²„ì „
- **medium**: 1.5B íŒŒë¼ë¯¸í„°, ê· í˜•ì¡íŒ ì„±ëŠ¥
- **large**: 3.3B íŒŒë¼ë¯¸í„°, ìµœê³  í’ˆì§ˆ

#### ğŸ¼ íŠ¹ìˆ˜ ëª¨ë¸
- **melody**: ë©œë¡œë”” ì¡°ê±´ë¶€ ìƒì„± ì§€ì›
- **style**: ìŠ¤íƒ€ì¼ ì¡°ê±´ë¶€ ìƒì„± ì§€ì› (ìµœì‹  ì¶”ê°€)

### ë¡œë”© ë©”ì»¤ë‹ˆì¦˜

```python
@staticmethod
def get_pretrained(name: str = 'facebook/musicgen-medium', device=None):
    """Return pretrained model, we provide a few models out of the box.
    
    Available models:
    - facebook/musicgen-small: 300M model, text to music
    - facebook/musicgen-medium: 1.5B model, text to music  
    - facebook/musicgen-large: 3.3B model, text to music
    - facebook/musicgen-melody: 1.5B model, text to music and text+melody to music
    - facebook/musicgen-style: 1.5B model, text to music and text+style to music
    """
```

ê° ëª¨ë¸ì€ Hugging Face Hubì—ì„œ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë˜ë©°, ë¡œì»¬ ìºì‹œë¥¼ í†µí•´ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬ë©ë‹ˆë‹¤.

## ìƒì„± íŒŒë¼ë¯¸í„° ì„¤ì •

### í•µì‹¬ ìƒì„± íŒŒë¼ë¯¸í„°

```python
def set_generation_params(self, use_sampling: bool = True, top_k: int = 250,
                         top_p: float = 0.0, temperature: float = 1.0, 
                         duration: float = 30.0, cfg_coef: float = 3.0,
                         cfg_coef_beta: tp.Optional[float] = None,
                         two_step_cfg: bool = False, extend_stride: float = 18):
```

#### ğŸ›ï¸ ìƒ˜í”Œë§ ì œì–´
- **use_sampling**: ìƒ˜í”Œë§ vs. argmax ë””ì½”ë”© ì„ íƒ
- **top_k**: ìƒìœ„ kê°œ í† í°ì—ì„œ ìƒ˜í”Œë§ (ê¸°ë³¸ê°’: 250)
- **top_p**: ëˆ„ì  í™•ë¥  ì„ê³„ê°’ (0ì´ë©´ top_k ì‚¬ìš©)
- **temperature**: ì†Œí”„íŠ¸ë§¥ìŠ¤ ì˜¨ë„ íŒŒë¼ë¯¸í„°

#### â±ï¸ ìƒì„± ê¸¸ì´ ì œì–´
- **duration**: ìƒì„±í•  ìŒì•…ì˜ ê¸¸ì´ (ì´ˆ)
- **extend_stride**: 30ì´ˆ ì´ìƒ ìƒì„± ì‹œ í™•ì¥ ê°„ê²©

#### ğŸ¯ ë¶„ë¥˜ê¸° ì—†ëŠ” ê°€ì´ë˜ìŠ¤ (CFG)
- **cfg_coef**: CFG ê³„ìˆ˜ (ê¸°ë³¸ê°’: 3.0)
- **cfg_coef_beta**: ì´ì¤‘ CFGìš© ë² íƒ€ ê³„ìˆ˜ (ë©œë¡œë”” ëª¨ë¸ìš©)
- **two_step_cfg**: ë°°ì¹˜ ëŒ€ì‹  2ë‹¨ê³„ ì „ì§„ ìˆ˜í–‰

### ìŠ¤íƒ€ì¼ ì¡°ê±´ì íŒŒë¼ë¯¸í„°

```python
def set_style_conditioner_params(self, eval_q: int = 3, excerpt_length: float = 3.0,
                                ds_factor: tp.Optional[int] = None,
                                encodec_n_q: tp.Optional[int] = None):
    """ìŠ¤íƒ€ì¼ ì¡°ê±´ìì˜ íŒŒë¼ë¯¸í„° ì„¤ì •
    
    Args:
        eval_q: ìŠ¤íƒ€ì¼ ì¡°ê±´ ì–‘ìí™”ì— ì‚¬ìš©í•  ì”ì—¬ ì–‘ìí™” ìŠ¤íŠ¸ë¦¼ ìˆ˜
        excerpt_length: ì˜¤ë””ì˜¤ ì¡°ê±´ì—ì„œ ì¶”ì¶œí•  ë°œì·Œ ê¸¸ì´ (ì´ˆ)
        ds_factor: ìŠ¤íƒ€ì¼ í† í°ì„ ì ‘ë‘ì‚¬ë¡œ ì‚¬ìš©í•˜ê¸° ì „ ë‹¤ìš´ìƒ˜í”Œë§ íŒ©í„°
        encodec_n_q: EnCodecì´ íŠ¹ì§• ì¶”ì¶œê¸°ë¡œ ì‚¬ìš©ë  ë•Œì˜ ìŠ¤íŠ¸ë¦¼ ìˆ˜
    """
```

## ì¡°ê±´ë¶€ ìƒì„± ë©”ì»¤ë‹ˆì¦˜

### í…ìŠ¤íŠ¸ ì¡°ê±´ë¶€ ìƒì„±

```python
@torch.no_grad()
def generate(self, descriptions: tp.List[str], progress: bool = False, 
             return_tokens: bool = False) -> torch.Tensor:
    """í…ìŠ¤íŠ¸ ì„¤ëª…ì—ì„œ ì˜¤ë””ì˜¤ ìƒì„±
    
    Args:
        descriptions: í…ìŠ¤íŠ¸ ì¡°ê±´ìœ¼ë¡œ ì‚¬ìš©í•  ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
        progress: ìƒì„± ê³¼ì • ì§„í–‰ë¥  í‘œì‹œ ì—¬ë¶€
        return_tokens: í† í° ë°˜í™˜ ì—¬ë¶€
    """
```

#### ğŸ“ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ê³¼ì •
1. **ì†ì„± ìƒì„±**: ê° ì„¤ëª…ì„ `ConditioningAttributes`ë¡œ ë³€í™˜
2. **í† í°í™”**: í…ìŠ¤íŠ¸ë¥¼ ì–¸ì–´ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í† í°ìœ¼ë¡œ ë³€í™˜
3. **ì„ë² ë”©**: í† í°ì„ ê³ ì°¨ì› ë²¡í„° ê³µê°„ìœ¼ë¡œ ë§¤í•‘

### ë©œë¡œë”” ì¡°ê±´ë¶€ ìƒì„±

```python
@torch.no_grad()
def generate_with_chroma(self, descriptions: tp.List[str], 
                        melody_wavs: MelodyList,
                        melody_sample_rate: int = 32000,
                        progress: bool = False, 
                        return_tokens: bool = False) -> torch.Tensor:
    """í…ìŠ¤íŠ¸ì™€ í¬ë¡œë§ˆ ì¡°ê±´ìœ¼ë¡œ ìŒì•… ìƒì„±"""
```

#### ğŸµ ë©œë¡œë”” ì²˜ë¦¬ ë©”ì»¤ë‹ˆì¦˜
1. **ì˜¤ë””ì˜¤ ë³€í™˜**: ë©œë¡œë”” íŒŒí˜•ì„ ëª¨ë¸ì˜ ìƒ˜í”Œë ˆì´íŠ¸ë¡œ ë³€í™˜
2. **í¬ë¡œë§ˆ ì¶”ì¶œ**: ë©œë¡œë””ì—ì„œ í¬ë¡œë§ˆ íŠ¹ì§• ì¶”ì¶œ
3. **ì¡°ê±´ ê²°í•©**: í…ìŠ¤íŠ¸ì™€ ë©œë¡œë”” ì¡°ê±´ì„ ê²°í•©

### ì¡°ê±´ ì¤€ë¹„ ê³¼ì •

```python
def _prepare_tokens_and_attributes(
        self,
        descriptions: tp.Sequence[tp.Optional[str]],
        prompt: tp.Optional[torch.Tensor],
        melody_wavs: tp.Optional[MelodyList] = None,
) -> tp.Tuple[tp.List[ConditioningAttributes], tp.Optional[torch.Tensor]]:
    """ëª¨ë¸ ì…ë ¥ ì¤€ë¹„"""
```

#### ğŸ”„ ì†ì„± êµ¬ì„±
```python
attributes = [
    ConditioningAttributes(text={'description': description})
    for description in descriptions]
```

#### ğŸ¼ ë©œë¡œë”” ì¡°ê±´ ì²˜ë¦¬
```python
if melody_wavs is None:
    # ë¹ˆ ì¡°ê±´ ìƒì„±
    attr.wav['self_wav'] = WavCondition(
        torch.zeros((1, 1, 1), device=self.device),
        torch.tensor([0], device=self.device),
        sample_rate=[self.sample_rate],
        path=[None])
else:
    # ì‹¤ì œ ë©œë¡œë”” ì¡°ê±´ ì²˜ë¦¬
    for attr, melody in zip(attributes, melody_wavs):
        # ë©œë¡œë”” íŒŒí˜•ì„ ì¡°ê±´ìœ¼ë¡œ ì„¤ì •
```

## í† í° ìƒì„± ê³¼ì •

### ë‹¨ì¼ ë‹¨ê³„ ìƒì„± (â‰¤30ì´ˆ)

```python
if self.duration <= self.max_duration:
    # LMì—ì„œ ìƒ˜í”Œë§í•˜ì—¬ ìƒì„±, ë‹¨ìˆœí•œ ê²½ìš°
    with self.autocast:
        gen_tokens = self.lm.generate(
            prompt_tokens, attributes,
            callback=callback, max_gen_len=total_gen_len, 
            **self.generation_params)
```

### í™•ì¥ ìƒì„± (>30ì´ˆ)

```python
else:
    # í”„ë¡¬í”„íŠ¸, ë©œë¡œë”” ì¡°ê±´ ë“±ì„ ì²˜ë¦¬í•˜ëŠ” ë³µì¡í•œ ê²½ìš°
    ref_wavs = [attr.wav['self_wav'] for attr in attributes]
    all_tokens = []
    
    # ì„¸ê·¸ë¨¼íŠ¸ë³„ ìƒì„±
    while current_gen_offset + prompt_length < total_gen_len:
        # ê° ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´ í† í° ìƒì„±
        # ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´ì„ ìœ„í•œ ì¤‘ë³µ ì²˜ë¦¬
```

#### ğŸ”„ í™•ì¥ ìƒì„±ì˜ íŠ¹ì§•
1. **ì„¸ê·¸ë¨¼íŠ¸ ë¶„í• **: ê¸´ ìŒì•…ì„ ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë‚˜ëˆ„ì–´ ìƒì„±
2. **ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´**: `extend_stride`ë¥¼ í†µí•œ ì¤‘ë³µ ì˜ì—­ ìœ ì§€
3. **ì¡°ê±´ ìœ ì§€**: ì „ì²´ ìƒì„± ê³¼ì •ì—ì„œ í…ìŠ¤íŠ¸/ë©œë¡œë”” ì¡°ê±´ ì¼ê´€ì„± ìœ ì§€

### ì§„í–‰ë¥  ì½œë°±

```python
def _progress_callback(generated_tokens: int, tokens_to_generate: int):
    generated_tokens += current_gen_offset
    if self._progress_callback is not None:
        self._progress_callback(generated_tokens, tokens_to_generate)
    else:
        print(f'{generated_tokens: 6d} / {tokens_to_generate: 6d}', end='\r')
```

## ì„±ëŠ¥ ìµœì í™” ê¸°ë²•

### ìë™ í˜¼í•© ì •ë°€ë„ (AMP)

```python
if self.device.type == 'cpu':
    self.autocast = TorchAutocast(enabled=False)
else:
    self.autocast = TorchAutocast(
        enabled=True, device_type=self.device.type, dtype=torch.float16)
```

#### ğŸ’¡ ìµœì í™” íš¨ê³¼
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ**: float16 ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
- **ê³„ì‚° ì†ë„ í–¥ìƒ**: GPUì—ì„œ mixed precision ì—°ì‚° ê°€ì†
- **ì •í™•ë„ ìœ ì§€**: ì¤‘ìš”í•œ ì—°ì‚°ì€ float32ë¡œ ìë™ ì „í™˜

### ë””ë°”ì´ìŠ¤ ê´€ë¦¬

```python
self.device = next(iter(lm.parameters())).device
```

ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ê°€ ìœ„ì¹˜í•œ ë””ë°”ì´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬ ì¼ê´€ëœ ë””ë°”ì´ìŠ¤ ì‚¬ìš©ì„ ë³´ì¥í•©ë‹ˆë‹¤.

### ì¡°ê±´ë¶€ ê³„ì‚°

```python
# ëª¨ë¸ì´ ë©œë¡œë”” ì¡°ê±´ì„ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸
if 'self_wav' not in self.lm.condition_provider.conditioners:
    raise RuntimeError("This model doesn't support melody conditioning. "
                       "Use the `melody` model.")
```

ë¶ˆí•„ìš”í•œ ê³„ì‚°ì„ ë°©ì§€í•˜ê³  ëª¨ë¸ í˜¸í™˜ì„±ì„ ì‚¬ì „ì— ê²€ì¦í•©ë‹ˆë‹¤.

## ğŸ” í•µì‹¬ ì¸ì‚¬ì´íŠ¸

### 1. ëª¨ë“ˆí™”ëœ ì•„í‚¤í…ì²˜
- **ë¶„ë¦¬ëœ ê´€ì‹¬ì‚¬**: ì••ì¶•, ì–¸ì–´ ëª¨ë¸ë§, ì¡°ê±´ ì²˜ë¦¬ê°€ ë…ë¦½ì ìœ¼ë¡œ êµ¬í˜„
- **í™•ì¥ì„±**: ìƒˆë¡œìš´ ì¡°ê±´ íƒ€ì…ì´ë‚˜ ëª¨ë¸ í¬ê¸° ì‰½ê²Œ ì¶”ê°€ ê°€ëŠ¥

### 2. ìœ ì—°í•œ ìƒì„± ì œì–´
- **ë‹¤ì–‘í•œ ìƒ˜í”Œë§ ì „ëµ**: top-k, top-p, temperature ì¡°í•©
- **ì ì§„ì  ìƒì„±**: ê¸´ ìŒì•…ë„ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ìƒì„±

### 3. ì¡°ê±´ë¶€ ìƒì„±ì˜ ì •êµí•¨
- **ë‹¤ì¤‘ ì¡°ê±´ ì§€ì›**: í…ìŠ¤íŠ¸, ë©œë¡œë””, ìŠ¤íƒ€ì¼ ë™ì‹œ ì²˜ë¦¬
- **ì¡°ê±´ ê²€ì¦**: ëª¨ë¸ í˜¸í™˜ì„± ì‚¬ì „ í™•ì¸

### 4. ì„±ëŠ¥ ìµœì í™”
- **ìë™ ìµœì í™”**: ë””ë°”ì´ìŠ¤ë³„ ìµœì  ì„¤ì • ìë™ ì„ íƒ
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: í˜¼í•© ì •ë°€ë„ì™€ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±

## ğŸ¯ ê²°ë¡ 

MusicGenì˜ êµ¬í˜„ì€ í˜„ëŒ€ì ì¸ AI ìŒì•… ìƒì„±ì˜ ë³µì¡ì„±ì„ ì˜ ë³´ì—¬ì¤ë‹ˆë‹¤. ì–¸ì–´ ëª¨ë¸ì˜ ê°•ë ¥í•¨ê³¼ ì˜¤ë””ì˜¤ ì²˜ë¦¬ì˜ ì •êµí•¨ì„ ê²°í•©í•˜ì—¬, ì‚¬ìš©ì ì¹œí™”ì ì¸ API ë’¤ì— ìˆ¨ì–´ìˆëŠ” ë³µì¡í•œ ë©”ì»¤ë‹ˆì¦˜ë“¤ì„ íš¨ê³¼ì ìœ¼ë¡œ ì¶”ìƒí™”í–ˆìŠµë‹ˆë‹¤.

ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„œëŠ” AudioGenê³¼ EnCodecì˜ êµ¬í˜„ì„ ì‚´í´ë³´ë©°, ìŒì•… ìƒì„±ê³¼ ì¼ë°˜ ì˜¤ë””ì˜¤ ìƒì„±ì˜ ì°¨ì´ì , ê·¸ë¦¬ê³  ì‹ ê²½ë§ ì˜¤ë””ì˜¤ ì••ì¶•ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.

---

*ì´ ë¶„ì„ì€ AudioCraft Custom í”„ë¡œì íŠ¸ì˜ ì‹¤ì œ ì†ŒìŠ¤ ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ë” ìì„¸í•œ êµ¬í˜„ ë‚´ìš©ì€ [AudioCraft ê³µì‹ ì €ì¥ì†Œ](https://github.com/facebookresearch/audiocraft)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.*